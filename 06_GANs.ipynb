{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "12-GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P0dH-wfiDv2L"
      },
      "source": [
        "# Generative Adversarial Networks\n",
        "\n",
        "In this notebook we will experiment with Generative Adversarial Networks for superresolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UevhtR-ezQnX",
        "colab": {}
      },
      "source": [
        "!pip install scipy==1.1.0\n",
        "!wget --output-document sres.zip https://github.com/mlcollege/deep-learning-rb/blob/master/data/sres.zip?raw=true\n",
        "!unzip sres.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x6LvNkh1nmZa"
      },
      "source": [
        "Define data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zGhBaCCzDhlc",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, mode = 'L'):\n",
        "        self.mode =  mode\n",
        "        self.input_shape = None\n",
        "        self.output_shape = None\n",
        "        \n",
        "    \n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode=self.mode).astype(np.float)\n",
        "\n",
        "    def load_data(self, batch_size=1, is_testing=False):\n",
        "        data_type = \"train\" if not is_testing else \"test\"\n",
        "        \n",
        "        path = glob('./sres/{}/source/*'.format(data_type))\n",
        "\n",
        "        batch_images = np.random.choice(path, size=batch_size) if not is_testing else path\n",
        "\n",
        "        imgs_src = []\n",
        "        imgs_trg = []\n",
        "        for img_path in batch_images:\n",
        "            img_src = self.imread(img_path)\n",
        "            img_trg = self.imread(img_path.replace('source', 'target'))\n",
        "\n",
        "            img_src = np.expand_dims(img_src, axis=3) \n",
        "            img_trg = np.expand_dims(img_trg, axis=3) \n",
        "            \n",
        "            imgs_trg.append(img_trg)\n",
        "            imgs_src.append(img_src)\n",
        "\n",
        "        imgs_trg = np.array(imgs_trg) / 127.5 - 1.\n",
        "        imgs_src = np.array(imgs_src) / 127.5 - 1.\n",
        "        self.input_shape = imgs_src.shape[1:]\n",
        "        self.output_shape = imgs_trg.shape[1:]\n",
        "\n",
        "        return imgs_src, imgs_trg\n",
        "\n",
        "    def single_img(self, file_name):\n",
        "        img_src = self.imread(file_name)\n",
        "        img_src = np.expand_dims(img_src, axis=3)\n",
        "        return np.array([img_src]) / 127.5 - 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ZErpIGRoY0y"
      },
      "source": [
        "Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "naOyM729oanK",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import scipy\n",
        "import datetime\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, Add\n",
        "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "\n",
        "class SRGAN:\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.channels = 1\n",
        "        self.width = output_size[0]\n",
        "        self.height = output_size[1]\n",
        "        self.shape = (self.height, self.width, self.channels)\n",
        "        self.input_shape = (input_size[1], input_size[0], self.channels)\n",
        "\n",
        "        # Number of residual blocks in the generator\n",
        "        self.n_residual_blocks = 16\n",
        "\n",
        "        # Number of filters in the first layer of G and D\n",
        "        self.gf = 64\n",
        "        self.df = 64\n",
        "\n",
        "        zoom = output_size[0] // input_size[0]\n",
        "        self.upsampling_levels = int(np.log(zoom)/np.log(2))\n",
        "\n",
        "\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        patch_width = -(-self.width // 2**4)\n",
        "        patch_height = -(-self.height // 2**4)\n",
        "        self.disc_patch = (patch_height, patch_width, 1)\n",
        "\n",
        "        self.optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # We use a pre-trained VGG19 model to extract image features from the target\n",
        "        # image and the generated images and minimize the mse between them\n",
        "        self.vgg = self.get_vgg()\n",
        "\n",
        "        self.discriminator = self.get_discriminator()\n",
        "\n",
        "        self.generator = self.get_generator()\n",
        "\n",
        "        self.gan = self.get_gan(self.discriminator, self.generator)\n",
        "\n",
        "    def get_vgg(self):\n",
        "        \"\"\"\n",
        "        Builds a pre-trained VGG19 model that outputs image features extracted at the\n",
        "        third block of the model\n",
        "        \"\"\"\n",
        "        # Set outputs to outputs of last conv. layer in block 3\n",
        "        vgg19 = VGG19(weights=\"imagenet\")\n",
        "        vgg19.outputs = [vgg19.layers[9].output]\n",
        "\n",
        "        # Extract image features\n",
        "        vgg_input = Input(shape=self.shape)\n",
        "        a = Dense(3)(vgg_input)\n",
        "        vgg_output = vgg19(a)\n",
        "        \n",
        "        #build the model\n",
        "        vgg = Model(inputs=vgg_input, outputs=vgg_output)\n",
        "        vgg.trainable = False\n",
        "        vgg.compile(loss='mse', optimizer=self.optimizer)\n",
        "        \n",
        "        return vgg\n",
        "\n",
        "    def get_discriminator(self):\n",
        "        \"\"\"\n",
        "        Builds the discriminator\n",
        "        \"\"\"\n",
        "\n",
        "        def d_block(layer_input, filters, strides=1, bn=True):\n",
        "            \"\"\"Discriminator layer\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
        "            d = LeakyReLU(alpha=0.2)(d)\n",
        "            if bn:\n",
        "                d = BatchNormalization(momentum=0.8)(d)\n",
        "            return d\n",
        "\n",
        "        disc_input = Input(shape=self.shape)\n",
        "        \n",
        "        d1 = d_block(disc_input, self.df, bn=False)\n",
        "        d2 = d_block(d1, self.df, strides=2)\n",
        "        d3 = d_block(d2, self.df*2)\n",
        "        d4 = d_block(d3, self.df*2, strides=2)\n",
        "        d5 = d_block(d4, self.df*4)\n",
        "        d6 = d_block(d5, self.df*4, strides=2)\n",
        "        d7 = d_block(d6, self.df*8)\n",
        "        d8 = d_block(d7, self.df*8, strides=2)\n",
        "        d9 = Dense(self.df*16)(d8)\n",
        "        d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "        \n",
        "        disc_output = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "        discriminator = Model(inputs=disc_input, outputs=disc_output)\n",
        "        discriminator.compile(loss='binary_crossentropy',\n",
        "            optimizer=self.optimizer)\n",
        "\n",
        "        return discriminator\n",
        "\n",
        "        \n",
        "    def get_generator(self):\n",
        "        \"\"\"\n",
        "        Builds the generator\n",
        "        \"\"\"\n",
        "        def residual_block(layer_input, filters):\n",
        "            \"\"\"Residual block described in the SRGAN paper\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
        "            d = Activation('relu')(d)\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "            d = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
        "            d = BatchNormalization(momentum=0.8)(d)\n",
        "            d = Add()([d, layer_input])\n",
        "            return d\n",
        "\n",
        "        def deconv2d(layer_input):\n",
        "            \"\"\"Layers used during upsampling\"\"\"\n",
        "            u = UpSampling2D(size=2)(layer_input)\n",
        "            u = Conv2D(256, kernel_size=3, strides=1, padding='same')(u)\n",
        "            u = Activation('relu')(u)\n",
        "            return u\n",
        "\n",
        "        gen_input = Input(shape=self.input_shape)\n",
        "\n",
        "        # Pre-residual block\n",
        "        c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(gen_input)\n",
        "        c1 = Activation('relu')(c1)\n",
        "\n",
        "        # Propogate through residual blocks\n",
        "        r = residual_block(c1, self.gf)\n",
        "        for _ in range(self.n_residual_blocks - 1):\n",
        "            r = residual_block(r, self.gf)\n",
        "\n",
        "        # Post-residual block\n",
        "        c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
        "        c2 = BatchNormalization(momentum=0.8)(c2)\n",
        "        c2 = Add()([c2, c1])\n",
        "\n",
        "        # Upsampling\n",
        "        upsampling_hierarchy = [c2]\n",
        "        for ul in range(self.upsampling_levels):\n",
        "            upsampling_hierarchy.append(deconv2d(upsampling_hierarchy[-1]))\n",
        "\n",
        "        gen_output = Conv2D(self.channels, \n",
        "            kernel_size=9, strides=1, padding='same', activation='tanh')(upsampling_hierarchy[-1])\n",
        "\n",
        "        generator = Model(inputs=gen_input, outputs=gen_output)\n",
        "        generator.compile(loss='mse', optimizer=self.optimizer)\n",
        "        return generator\n",
        "\n",
        "    def get_gan(self, discriminator, generator):\n",
        "        \"\"\"\n",
        "        Builds the combined model of generator and discriminator\n",
        "        \"\"\"\n",
        "        \n",
        "        source_img = Input(shape=self.input_shape)\n",
        "        target_img = Input(shape=self.shape)\n",
        "\n",
        "        #generate fake image\n",
        "        fake_target = generator(source_img)\n",
        "        #generate features of the fake image\n",
        "        fake_features = self.vgg(fake_target)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        # Discriminator determines validity of the generated images\n",
        "        validity = discriminator(fake_target)\n",
        "\n",
        "        #build the model\n",
        "        gan = Model([source_img, target_img], [validity, fake_features])\n",
        "        gan.compile(loss=['binary_crossentropy', 'mse'],\n",
        "                              loss_weights=[1e-3, 1],\n",
        "                              optimizer=self.optimizer)\n",
        "        return gan\n",
        "\n",
        "    def train(self, data_loader, epochs=1000, batch_size=1, sample_interval=5):\n",
        "\n",
        "        print(\"Training\")\n",
        "\n",
        "        start_time = datetime.datetime.now()\n",
        "        for epoch in range(epochs):\n",
        "            # ----------------------\n",
        "            #  Train Discriminator\n",
        "            # ----------------------\n",
        "\n",
        "            self.discriminator.trainable = True\n",
        "    \n",
        "            # Sample images\n",
        "            source_img, target_img = data_loader.load_data(batch_size)\n",
        "\n",
        "\n",
        "            #generate fake target\n",
        "            fake_target = self.generator.predict(source_img)\n",
        "\n",
        "            # Train the discriminators (original images = real / generated = Fake)\n",
        "            valid = np.ones((batch_size,) + self.disc_patch)\n",
        "            fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "            d_loss_real = self.discriminator.train_on_batch(target_img, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(fake_target, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ------------------\n",
        "            #  Train Generator\n",
        "            # ------------------\n",
        "\n",
        "            self.discriminator.trainable = False\n",
        "            \n",
        "            # Sample images\n",
        "            source_img, target_img = data_loader.load_data(batch_size)\n",
        "\n",
        "            # The generator wants the discriminators to label the generated images as real\n",
        "            valid = np.ones((batch_size,) + self.disc_patch)\n",
        "           \n",
        "            # Extract ground truth image features using pre-trained VGG19 model\n",
        "            image_features = self.vgg.predict(target_img)\n",
        "\n",
        "            # Train the generator\n",
        "            g_loss = self.gan.train_on_batch([source_img, target_img], [valid, image_features])\n",
        "\n",
        "            elapsed_time = datetime.datetime.now() - start_time\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"Epoch %d,  time: %s, D-loss: %f, G1-loss: %f, G2-loss: %f\" % (epoch, elapsed_time, d_loss, g_loss[0], g_loss[1]))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(data_loader, epoch)\n",
        "                self.save(epoch)\n",
        "\n",
        "    def save(self, filePrefix):\n",
        "        os.makedirs('models', exist_ok=True)\n",
        "        self.discriminator.save_weights('models/{}.dsc.h5'.format(filePrefix))\n",
        "        self.generator.save_weights('models/{}.gen.h5'.format(filePrefix))\n",
        "        self.gan.save_weights('models/{}.gan.h5'.format( filePrefix))\n",
        "    \n",
        "    def load(self,  filePrefix):\n",
        "        print (\"Loading models.\")\n",
        "        self.discriminator.load_weights('models/{}.dsc.h5'.format(filePrefix))\n",
        "        self.generator.load_weights('models/{}.gen.h5'.format(filePrefix))\n",
        "        self.gan.load_weights('models/{}.gan.h5'.format(filePrefix))\n",
        "\n",
        "    def predict(self, data_loader, file_name):\n",
        "        print (\"Predicting..\")\n",
        "        imgs_src = data_loader.single_img(file_name)\n",
        "        imgs_fk = self.generator.predict(imgs_src).reshape(self.height, self.width)\n",
        "        Image.fromarray(((imgs_fk + 1)*127.5).astype(np.uint8), mode='L').save(file_name+'-gen.png')\n",
        "\n",
        "    def sample_images(self, data_loader, epoch):\n",
        "        os.makedirs('results', exist_ok=True)\n",
        "\n",
        "        imgs_src, imgs_trg = data_loader.load_data(batch_size=1, is_testing=True)\n",
        "        imgs_fk = self.generator.predict(imgs_src)\n",
        "        imgs_src = np.reshape(imgs_src, (imgs_src.shape[0], self.input_shape[0], self.input_shape[1]))\n",
        "        imgs_trg = np.reshape(imgs_trg, (imgs_trg.shape[0], self.height, self.width))\n",
        "        imgs_fk = np.reshape(imgs_fk, (imgs_fk.shape[0], self.height, self.width))\n",
        "\n",
        "        for index in range(imgs_src.shape[0]):\n",
        "            Image.fromarray(((imgs_src[index,:,:] + 1)*127.5).astype(np.uint8), mode='L').save(os.path.join(\"results/{}-img_src-{}.png\".format(epoch, index)))\n",
        "            Image.fromarray(((imgs_trg[index,:,:] + 1)*127.5).astype(np.uint8), mode='L').save(os.path.join(\"results/{}-img_trg-{}.png\".format(epoch, index)))\n",
        "            Image.fromarray(((imgs_fk[index,:,:] + 1)*127.5).astype(np.uint8), mode='L').save(os.path.join(\"results/{}-img_fk-{}.png\".format(epoch, index)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RoJ02eAApRKo"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yrnibKw6pOYZ",
        "colab": {}
      },
      "source": [
        "input_size = (128, 128)\n",
        "output_size = (512, 512)\n",
        "\n",
        "dl = DataLoader()\n",
        "deconvgan = SRGAN(input_size, output_size)\n",
        "deconvgan.train(dl, epochs=10, batch_size=1, sample_interval=100)\n",
        "#deconvgan.train(dl, epochs=3000, batch_size=1, sample_interval=100)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rGPwENes18IV",
        "colab": {}
      },
      "source": [
        "#!mkdir models\n",
        "#!wget --output-document models/gan.zip http://www.mlcollege.com/data/gan.zip\n",
        "#!unzip models/gan.zip\n",
        "#!mv *.h5 models/\n",
        "\n",
        "#dl = DataLoader()\n",
        "#deconvgan.load('3000')\n",
        "from PIL import Image\n",
        "deconvgan.predict(dl, 'sres/test/source/0.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "agx6XP8nbM4b",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image('sres/test/source/0.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ef_FEdCbiYr",
        "colab": {}
      },
      "source": [
        "Image('sres/test/source/0.png-gen.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p3QBZ8PFblNu",
        "colab": {}
      },
      "source": [
        "Image('sres/test/target/0.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjxQAB8JyV16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}