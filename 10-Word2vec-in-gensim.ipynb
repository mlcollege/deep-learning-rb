{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec in Gensim\n",
    "\n",
    "Implement a simple word2vec estimator using [Gensim](https://radimrehurek.com/gensim/). Use the small Wikipedia corpus from '../data/corpora/enlang1.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-07 14:53:36,962 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-02-07 14:53:36,963 : INFO : collecting all words and their counts\n",
      "2019-02-07 14:53:36,964 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-02-07 14:53:37,893 : INFO : collected 175177 word types from a corpus of 4873383 raw words and 5000 sentences\n",
      "2019-02-07 14:53:37,894 : INFO : Loading a fresh vocabulary\n",
      "2019-02-07 14:53:38,365 : INFO : min_count=3 retains 62837 unique words (35% of original 175177, drops 112340)\n",
      "2019-02-07 14:53:38,365 : INFO : min_count=3 leaves 4736664 word corpus (97% of original 4873383, drops 136719)\n",
      "2019-02-07 14:53:38,588 : INFO : deleting the raw counts dictionary of 175177 items\n",
      "2019-02-07 14:53:38,595 : INFO : sample=0.001 downsamples 26 most-common words\n",
      "2019-02-07 14:53:38,596 : INFO : downsampling leaves estimated 3788259 word corpus (80.0% of prior 4736664)\n",
      "2019-02-07 14:53:38,849 : INFO : estimated required memory for 62837 words and 50 dimensions: 56553300 bytes\n",
      "2019-02-07 14:53:38,850 : INFO : resetting layer weights\n",
      "2019-02-07 14:53:39,592 : INFO : training model with 3 workers on 62837 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-07 14:53:40,600 : INFO : EPOCH 1 - PROGRESS: at 25.34% examples, 1017229 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 14:53:41,604 : INFO : EPOCH 1 - PROGRESS: at 54.46% examples, 1058482 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 14:53:42,607 : INFO : EPOCH 1 - PROGRESS: at 85.40% examples, 1085954 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 14:53:43,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 14:53:43,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 14:53:43,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 14:53:43,048 : INFO : EPOCH - 1 : training on 4873383 raw words (3778474 effective words) took 3.5s, 1094654 effective words/s\n",
      "2019-02-07 14:53:44,055 : INFO : EPOCH 2 - PROGRESS: at 29.22% examples, 1144582 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-07 14:53:45,074 : INFO : EPOCH 2 - PROGRESS: at 56.14% examples, 1085624 words/s, in_qsize 5, out_qsize 1\n",
      "2019-02-07 14:53:46,077 : INFO : EPOCH 2 - PROGRESS: at 83.50% examples, 1051359 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 14:53:46,624 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 14:53:46,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 14:53:46,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 14:53:46,637 : INFO : EPOCH - 2 : training on 4873383 raw words (3778336 effective words) took 3.6s, 1054546 effective words/s\n",
      "2019-02-07 14:53:47,645 : INFO : EPOCH 3 - PROGRESS: at 28.48% examples, 1120934 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 14:53:48,645 : INFO : EPOCH 3 - PROGRESS: at 59.10% examples, 1150010 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 14:53:49,648 : INFO : EPOCH 3 - PROGRESS: at 87.02% examples, 1108004 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 14:53:50,031 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 14:53:50,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 14:53:50,043 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 14:53:50,045 : INFO : EPOCH - 3 : training on 4873383 raw words (3778236 effective words) took 3.4s, 1110358 effective words/s\n",
      "2019-02-07 14:53:51,067 : INFO : EPOCH 4 - PROGRESS: at 27.28% examples, 1085257 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 14:53:52,077 : INFO : EPOCH 4 - PROGRESS: at 53.60% examples, 1032897 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-07 14:53:53,082 : INFO : EPOCH 4 - PROGRESS: at 83.24% examples, 1048394 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 14:53:53,590 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 14:53:53,605 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 14:53:53,614 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 14:53:53,615 : INFO : EPOCH - 4 : training on 4873383 raw words (3778255 effective words) took 3.6s, 1061903 effective words/s\n",
      "2019-02-07 14:53:54,633 : INFO : EPOCH 5 - PROGRESS: at 28.18% examples, 1113020 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 14:53:55,640 : INFO : EPOCH 5 - PROGRESS: at 56.14% examples, 1090074 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 14:53:56,652 : INFO : EPOCH 5 - PROGRESS: at 88.30% examples, 1115840 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 14:53:57,002 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 14:53:57,011 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 14:53:57,014 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 14:53:57,015 : INFO : EPOCH - 5 : training on 4873383 raw words (3779033 effective words) took 3.4s, 1115774 effective words/s\n",
      "2019-02-07 14:53:57,018 : INFO : training on a 24366915 raw words (18892334 effective words) took 17.4s, 1084201 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentences = []\n",
    "with open('../data/corpora/enlang1.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        sentences.append(line.strip().split())\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences, size = 50, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7218808  -0.4272013  -0.79122293 -4.145425    0.4663584   1.2451011\n",
      " -1.3500787   0.96638715 -1.7594365  -3.2623775  -1.5156037   4.202594\n",
      "  0.96996725 -1.3616059  -0.50863105 -0.11124986 -0.9238543  -0.7314218\n",
      " -1.1395476  -0.35831714  0.7078443   0.9052772  -1.2973964   0.14551657\n",
      "  1.2575114  -1.3295317  -1.308183    0.92065614  1.5180007  -1.0573603\n",
      "  1.1286033  -0.6752914   0.5298296  -2.511676    2.705531   -0.78752106\n",
      " -1.1190983   2.0153103   1.4105419  -0.02672557 -0.05394428 -2.2373958\n",
      "  0.26088235  0.02553769  1.0599087   0.11638223 -0.58372146 -2.910903\n",
      "  1.4348471   0.20868112]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['car'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('expressway', 0.7484003901481628),\n",
       " ('mezzanine', 0.7359848618507385),\n",
       " ('southbound', 0.7286300659179688),\n",
       " ('motorway', 0.7252560257911682),\n",
       " ('keilor', 0.7196506261825562),\n",
       " ('roads', 0.7130234241485596),\n",
       " ('northumberland', 0.7093843221664429),\n",
       " ('turnpike', 0.7042462825775146),\n",
       " ('bypass', 0.6979405879974365),\n",
       " ('junction', 0.696420431137085)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['queens', 'king'], negative=['queen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import better models\n",
    "\n",
    "Import word vectors trained on [Common Crawl](https://fasttext.cc/docs/en/english-vectors.html) corpus (600 B tokens) and play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-07 14:09:02,756 : INFO : loading projection weights from ../data/crawl-300.vec\n",
      "2019-02-07 14:11:44,898 : INFO : loaded (500000, 300) matrix from ../data/crawl-300.vec\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('../data/crawl-300.vec', binary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queens', 0.838758111000061),\n",
       " ('queen.', 0.6004167795181274),\n",
       " ('monarchs', 0.5899762511253357),\n",
       " ('Queen', 0.5859925150871277),\n",
       " ('empresses', 0.5775150656700134),\n",
       " ('princes', 0.5499585866928101),\n",
       " ('QUEEN', 0.5448766350746155),\n",
       " ('royals', 0.5442696213722229),\n",
       " ('princesses', 0.5383291840553284),\n",
       " ('royal', 0.5232111215591431)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['kings', 'queen'], negative=['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wife', 0.7529045343399048),\n",
       " ('daughter', 0.6500850915908813),\n",
       " ('mother-in-law', 0.6470040678977966),\n",
       " ('spouse', 0.6457177996635437),\n",
       " ('husbands', 0.633111298084259),\n",
       " ('mother', 0.6005339622497559),\n",
       " ('ex-husband', 0.5952433347702026),\n",
       " ('daughter-in-law', 0.5948172807693481),\n",
       " ('ex-wife', 0.5728636384010315),\n",
       " ('daughters', 0.5600826144218445)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['woman', 'husband'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Madrid', 0.8625081181526184),\n",
       " ('Barcelona', 0.7637038826942444),\n",
       " ('Sevilla', 0.6874054670333862),\n",
       " ('Seville', 0.6747833490371704),\n",
       " ('Malaga', 0.6494930386543274),\n",
       " ('Zaragoza', 0.645937442779541),\n",
       " ('Valencia', 0.6383104920387268),\n",
       " ('Alicante', 0.6115807890892029),\n",
       " ('Salamanca', 0.6041631102561951),\n",
       " ('Murcia', 0.6019024848937988)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['Paris', 'Spain'], negative=['France'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Vladimir', 0.644631028175354),\n",
       " ('Medvedev', 0.6112760901451111),\n",
       " ('Sergei', 0.5950400233268738),\n",
       " ('Dmitry', 0.5793238878250122),\n",
       " ('Oleg', 0.5696351528167725),\n",
       " ('Denis', 0.5639139413833618),\n",
       " ('Mikhail', 0.5574285387992859),\n",
       " ('Anatoly', 0.5540498495101929),\n",
       " ('Igor', 0.5533066987991333),\n",
       " ('Ivan', 0.5529454350471497)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['Donald', 'Putin'], negative=['Trump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
